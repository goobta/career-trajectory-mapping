{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "northern-homeless",
   "metadata": {},
   "source": [
    "# Alumni Education History Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-offense",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-throw",
   "metadata": {},
   "source": [
    "## Load Data From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.read_csv('alum-edu-hist.csv')\n",
    "edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-cigarette",
   "metadata": {},
   "source": [
    "## Basic Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-engine",
   "metadata": {},
   "source": [
    "### FSB + relevant data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-chrome",
   "metadata": {},
   "source": [
    "Only get people from FSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = edu[(edu['Major #1 Department'] == 'Management') | (edu['Major #2 Department'] == 'Management') | (edu['Minor #1 Department'] == 'Management') | (edu['Minor #2 Department'] == 'Management')]\n",
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-amber",
   "metadata": {},
   "source": [
    "Select people in the last 50 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus[(bus['Contact: Preferred Class Year'] >= (2020 - 50)) & (bus['Contact: Preferred Class Year'] <= 2020)]\n",
    "bus.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "living-declaration",
   "metadata": {},
   "source": [
    "Only get wpi alumni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus[bus['Education: Record Type'] == 'WPI Degree']\n",
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-kentucky",
   "metadata": {},
   "source": [
    "Ensure that only relevant degrees are being picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['Degree/Certificate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_degrees = ['Bachelor of Science', 'Master of Science',\n",
    "       'Master of Business Admin.', 'Master of Science in Mgmt.',\n",
    "       'Bachelor of Arts']\n",
    "accept_regex = '|'.join(accepted_degrees)\n",
    "bus = bus[bus['Degree/Certificate'].str.contains(accept_regex)]\n",
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-attempt",
   "metadata": {},
   "source": [
    "### Uniqueness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-invitation",
   "metadata": {},
   "source": [
    "Seems that we have duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['Contact: Full Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-payday",
   "metadata": {},
   "source": [
    "Duplicated names are for multiple degrees; should be fine to keep them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus[bus['Contact: Full Name'] == 'Akshay Rao']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-palace",
   "metadata": {},
   "source": [
    "## Generate final list of alumni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(bus['Contact: Full Name'].unique())\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-columbia",
   "metadata": {},
   "source": [
    "Write to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.json', 'w') as fh:\n",
    "    json.dump(names, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-ballet",
   "metadata": {},
   "source": [
    "# WPI Names to LinkedIn URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-occasion",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-winner",
   "metadata": {},
   "source": [
    "Enable tqdm pandas mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-substitute",
   "metadata": {},
   "source": [
    "## Create Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = input('Input your developer key: ')\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_id = input('Input your engine ID: ')\n",
    "engine_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = build('customsearch', 'v1', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-swiss",
   "metadata": {},
   "source": [
    "## Create Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-stress",
   "metadata": {},
   "source": [
    "Create search query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(row):\n",
    "    name = row['Contact: Full Name']    \n",
    "    res = service.cse().siterestrict().list(\n",
    "       q=f'-intitle:profiles {name}', cx=engine_id, num=1,\n",
    "       exactTerms='Worcester Polytechnic Institute').execute()\n",
    "#     res = service.cse().list(\n",
    "#         q=f'-intitle:profiles {name}', cx=engine_id, num=1,\n",
    "#         exactTerms='Worcester Polytechnic Institute').execute()\n",
    "    if res and 'items' in res:\n",
    "        return res['items'][0]['link']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-wealth",
   "metadata": {},
   "source": [
    "Reduce the size until we have the final funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit = 99\n",
    "#subset = bus[:limit]\n",
    "subset = bus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-milan",
   "metadata": {},
   "source": [
    "Generate all of the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-apollo",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cnt = 0\n",
    "subset['url'] = None\n",
    "for _, row in tqdm(subset.iterrows(), total=subset.shape[0]):\n",
    "    cnt += 1\n",
    "    subset['url'].iloc[cnt-1] = get_url(row)\n",
    "    time.sleep(0.6)\n",
    "        \n",
    "    if cnt % 250 == 0:\n",
    "        subset.to_csv('checkpoints/urls-{}.csv'.format(cnt), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-recipient",
   "metadata": {},
   "source": [
    "Write to a file just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-conjunction",
   "metadata": {},
   "source": [
    "# Scrape LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = pd.read_csv('subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-deputy",
   "metadata": {},
   "source": [
    "Load scraper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-firmware",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run scrape/scrape_to_json.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-compromise",
   "metadata": {},
   "source": [
    "Scrape Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2771f4-dd8b-4728-9806-df2117308397",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = backup[1000:1100]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-smile",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "scraped = []\n",
    "cnt = 1\n",
    "yield_ = tqdm(total=subset.shape[0], desc='Yield')\n",
    "for url in tqdm(subset[subset['url'].notna()]['url'], total=subset.shape[0], desc='Total'):\n",
    "    try:\n",
    "        scraped.append(scrape(url))\n",
    "        yield_.update(1)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    if cnt % 100 == 0:\n",
    "        with open(f'checkpoints/scrapped-300.json', 'w') as fh:\n",
    "            fh.write(json.dumps(list(scraped), default=str))\n",
    "            \n",
    "    cnt += 1\n",
    "yield_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-window",
   "metadata": {},
   "source": [
    "Save raw data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scrapped-1000-1100.json', 'w') as fh:\n",
    "    fh.write(json.dumps(list(scraped), default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-special",
   "metadata": {},
   "source": [
    "# Join and Combine Scraped and Internal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scrapped-1500.json', 'r') as fh:\n",
    "    scrapped = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-fitness",
   "metadata": {},
   "source": [
    "## High Level Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-regression",
   "metadata": {},
   "source": [
    "### Fix year / dates\n",
    "People sometimes don't include the month in their profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(info):\n",
    "    for job in info['professional']:\n",
    "        if not job['start_year']:\n",
    "            job['start_year'] = int(job['start_month'])\n",
    "            job['start_month'] = 'Jan'\n",
    "        else:\n",
    "            job['start_year'] = int(job['start_year'])\n",
    "            \n",
    "        if not job['end_year']:\n",
    "            job['end_year'] = int(job['end_month'])\n",
    "            job['end_month'] = 'Jan'\n",
    "        else:\n",
    "            job['end_year'] = int(job['end_year'])\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-casting",
   "metadata": {},
   "source": [
    "### Filter Out Incorrect Scrapped Profiles\n",
    "Right now, the only metric to ensure that the data is valid is if they went to WPI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for s in list(scrapped):\n",
    "    went_to_wpi = False\n",
    "    for edu in s['academic']:\n",
    "        if edu['name'] == 'Worcester Polytechnic Institute':\n",
    "           # data.append(year(s))\n",
    "            data.append(s)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-madness",
   "metadata": {},
   "source": [
    "## Create Derived Features\n",
    "Create the features first, then assign them one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-lease",
   "metadata": {},
   "source": [
    "### Years Since First Job\n",
    "Show how long the person spent in each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_since_first_job(info):\n",
    "    if not info['professional']:\n",
    "        return info\n",
    "    \n",
    "    first_job = info['professional'][0]['start_year']\n",
    "    \n",
    "    for job in info['professional']:\n",
    "        # HACK NEED TO FIX\n",
    "        job['years_since_start'] = job['start_year'] - first_job\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-reading",
   "metadata": {},
   "source": [
    "### Job Tenure\n",
    "How long the person has been at their current job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_tenure(info):\n",
    "    for job in info['professional']:\n",
    "        # HACK NEED TO FIX\n",
    "        job['tenure'] = max(job['end_year'] - job['start_year'], 1)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-welcome",
   "metadata": {},
   "source": [
    "### Alunni Education History Join\n",
    "Join the LinkedIn data against WPI's internal database. In terms of conflict, always prefer WPI's database to the LinkedIn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_edu_history(info):\n",
    "    history = subset.loc[subset['url'] == info['url']]\n",
    "    \n",
    "    # Delete any WPI data\n",
    "    edu_backup = info['academic'].copy()\n",
    "    joint_edu = []\n",
    "    for edu in edu_backup:\n",
    "        if edu['name'] != 'Worcester Polytechnic Institute':\n",
    "            joint_edu.append(edu)\n",
    "                \n",
    "    # Join with WPI Data\n",
    "    for i in range(history.shape[0]):\n",
    "        degree = history.iloc[i].fillna('None')\n",
    "        \n",
    "        joint_edu.append({\n",
    "            'name': 'Worcester Polytechnic Institute',\n",
    "            'type': degree['Degree/Certificate'],\n",
    "            'start': degree['Start Year'],\n",
    "            'end': degree['Degree Year'],\n",
    "            'major_1': degree['Major #1'],\n",
    "            'major_1_dept': degree['Major #1 Department'],\n",
    "            'major_2': degree['Major #2'],\n",
    "            'major_2_dept': degree['Major #2 Department'],\n",
    "            'minor_1': degree['Minor #1'],\n",
    "            'minor_1_dept': degree['Minor #1 Department'],\n",
    "            'minor_2': degree['Minor #2'],\n",
    "            'minor_2_dept': degree['Minor #2 Department'],\n",
    "        })\n",
    "            \n",
    "    # print(joint_edu)        \n",
    "    # edu_hist = sorted(joint_edu, key=lambda x: int(x['end']))\n",
    "    edu_hist = joint_edu\n",
    "    for i, edu in enumerate(edu_hist):\n",
    "        edu['order'] = i\n",
    "    \n",
    "    info['academic'] = edu_hist\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-pressing",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_edu_history(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-building",
   "metadata": {},
   "source": [
    "## Merge all modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-suspension",
   "metadata": {},
   "source": [
    "Create a super simple, parallelizable function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post(d):\n",
    "    d = years_since_first_job(d)\n",
    "    d = job_tenure(d)\n",
    "    d = merge_edu_history(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-regression",
   "metadata": {},
   "source": [
    "# Final Join\n",
    "Merge all of the data together and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-passport",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "final = [merge_edu_history(d) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-portsmouth",
   "metadata": {},
   "source": [
    "Write and save to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final.json', 'w') as fh:\n",
    "    fh.write(json.dumps(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
