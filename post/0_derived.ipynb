{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protecting-percentage",
   "metadata": {},
   "source": [
    "# Precompte Calculated Fields\n",
    "Tableau be slow af so use zippy Python to precompute everything and store it. Yeah, Tableau is that bad that I called _Python_ fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-velvet",
   "metadata": {},
   "source": [
    "## Load the raw, scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serial-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport json\\nwith open('scrapped.json', 'r') as fh:\\n    data = json.load(fh)\\ndata[0]\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "with open('scrapped.json', 'r') as fh:\n",
    "    data = json.load(fh)\n",
    "data[0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "harmful-privacy",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-060da75765f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('final.json', 'r') as fh:\n",
    "    mapping = json.load(fh)\n",
    "data = list(mapping.values())\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-compound",
   "metadata": {},
   "source": [
    "### Create test user to validate upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = lambda: data[0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-hundred",
   "metadata": {},
   "source": [
    "previous## Basic Cleaning\n",
    "This will all be outsourced to another script down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-strengthening",
   "metadata": {},
   "source": [
    "### Fix year / dates\n",
    "People sometimes don't include the month in their profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(info):\n",
    "    for job in info['professional']:\n",
    "        if not job['start_year']:\n",
    "            job['start_year'] = int(job['start_month'])\n",
    "            job['start_month'] = 'Jan'\n",
    "        else:\n",
    "            job['start_year'] = int(job['start_year'])\n",
    "            \n",
    "        if not job['end_year']:\n",
    "            job['end_year'] = int(job['end_month'])\n",
    "            job['end_month'] = 'Jan'\n",
    "        else:\n",
    "            job['end_year'] = int(job['end_year'])\n",
    "    return info\n",
    "\n",
    "data = [year(d) for d in data]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-jesus",
   "metadata": {},
   "source": [
    "## Create Derived Features\n",
    "I'll first create a bunch of helper functions + basic test--and then I'll assign everything at the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-george",
   "metadata": {},
   "source": [
    "### Years Since First Job\n",
    "Show how long the person spent in each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def years_since_first_job(info):\n",
    "    if not info['professional']:\n",
    "        return info\n",
    "    \n",
    "    first_job = info['professional'][0]['start_year']\n",
    "    \n",
    "    for job in info['professional']:\n",
    "        # HACK NEED TO FIX\n",
    "        job['years_since_start'] = job['start_year'] - first_job\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-genetics",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_since_first_job(user())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-stanley",
   "metadata": {},
   "source": [
    "### Job Tenure\n",
    "How long the person has been at their current job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_tenure(info):\n",
    "    for job in info['professional']:\n",
    "        # HACK NEED TO FIX\n",
    "        job['tenure'] = max(job['end_year'] - job['start_year'], 1)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-diving",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_tenure(user())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-finland",
   "metadata": {},
   "source": [
    "## TODO: Derived Features\n",
    "Just some cool ideas that I can't implement now, but might explore down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-union",
   "metadata": {},
   "source": [
    "### Company Tenure / Satisfaction\n",
    "Show how long the person spent at each company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-kinase",
   "metadata": {},
   "source": [
    "### Years Since WPI\n",
    "Basically the same thing as `Years Since First Job`, but this is assuming that the data is theta-joined with registrar data to get immediate post-WPI insights.\n",
    "\n",
    "Interesting insights could also be `Years since WPI`, and `Years since Last Degree`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-scholar",
   "metadata": {},
   "source": [
    "## Merge all modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-idaho",
   "metadata": {},
   "source": [
    "Create a super simple, parallelizable function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post(d):\n",
    "    d = years_since_first_job(d)\n",
    "    d = job_tenure(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-notebook",
   "metadata": {},
   "source": [
    "Since the size is small, we can just process this bad boy sequentially. TODO: parallelize when dealing with the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for d in data:\n",
    "    try:\n",
    "        new.append(post(d.copy()))\n",
    "    except:\n",
    "        print(d)\n",
    "        raise\n",
    "new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-westminster",
   "metadata": {},
   "source": [
    "Write to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed.json', 'w') as fh:\n",
    "    json.dump(new, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-momentum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
